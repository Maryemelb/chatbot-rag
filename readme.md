# ğŸ¤– Assistant RAG pour Support IT

[![Pipeline CI/CD](https://github.com/yourusername/rag-it-assistant/workflows/CI-CD/badge.svg)](https://github.com/yourusername/rag-it-assistant/actions)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## Table des matiÃ¨res

- [PrÃ©sentation](#prÃ©sentation)
- [FonctionnalitÃ©s](#fonctionnalitÃ©s)
- [Architecture](#architecture)
- [Stack Technique](#stack-technique)
- [Structure du Projet](#structure-du-projet)
- [Installation](#installation)
- [Configuration](#configuration)
- [Utilisation](#utilisation)
- [Documentation API](#documentation-api)
- [DÃ©ploiement](#dÃ©ploiement)
- [Monitoring](#monitoring)
- [Tests](#tests)

## PrÃ©sentation

Un assistant intelligent de support IT basÃ© sur la technologie RAG (Retrieval-Augmented Generation). Ce systÃ¨me prÃªt pour la production permet aux techniciens IT d'interroger la documentation interne (procÃ©dures, incidents et FAQ au format PDF) et de recevoir des rÃ©ponses prÃ©cises et contextualisÃ©es.

### Objectifs Principaux

-  RÃ©ponses rapides aux questions rÃ©currentes du support IT
-  Base de connaissances centralisÃ©e Ã  partir de documents PDF
-  Apprentissage continu via clustering des questions utilisateurs
-  DÃ©ploiement cloud-native sur Kubernetes

## âœ¨ FonctionnalitÃ©s

### CapacitÃ©s Principales

- **Pipeline RAG** : RÃ©cupÃ©ration et gÃ©nÃ©ration basÃ©es sur LangChain
- **Recherche SÃ©mantique** : Base de donnÃ©es vectorielle ChromaDB pour une recherche documentaire efficace
- **Authentification** : ContrÃ´le d'accÃ¨s sÃ©curisÃ© basÃ© sur JWT
- **Historique des RequÃªtes** : TraÃ§abilitÃ© complÃ¨te des interactions utilisateurs
- **Clustering ML** : Apprentissage non supervisÃ© pour identifier les thÃ©matiques frÃ©quentes
- **Faible Latence** : Suivi des temps de rÃ©ponse

### FonctionnalitÃ©s MLOps

- **Suivi d'ExpÃ©riences** : IntÃ©gration MLflow pour la reproductibilitÃ©
- **Automatisation CI/CD** : Pipeline GitHub Actions
- **Orchestration** : DÃ©ploiement Kubernetes avec Minikube/Lens

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI   â”‚â”€â”€â”€â”€â”€â–¶â”‚ Moteur RAG   â”‚â”€â”€â”€â”€â”€â–¶â”‚  ChromaDB   â”‚
â”‚   Backend   â”‚      â”‚ (LangChain)  â”‚      â”‚  Vecteurs   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                     â”‚
       â”‚                     â–¼
       â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚              â”‚  ModÃ¨le LLM  â”‚
       â”‚              â”‚ (Gemini/HF)  â”‚
       â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL  â”‚      â”‚    MLflow    â”‚
â”‚Base de donnÃ©esâ”‚    â”‚   Tracking   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flux de DonnÃ©es

1. **Ingestion PDF** : Le pdf est dÃ©coupÃ©s en chunks et vectorisÃ©
2. **Stockage Vectoriel** : Les embeddings sont stockÃ©s dans ChromaDB
3. **Traitement des RequÃªtes** : Les questions utilisateurs rÃ©cupÃ¨rent les chunks pertinents
4. **GÃ©nÃ©ration de RÃ©ponses** : Le LLM gÃ©nÃ¨re des rÃ©ponses Ã  partir du contexte
5. **Logging** : RequÃªtes, rÃ©ponses et mÃ©triques sauvegardÃ©s dans PostgreSQL
6. **Clustering** : Analyse pÃ©riodique pour identifier les thÃ©matiques communes

## ğŸ› ï¸ Stack Technique

### Backend & API
- **FastAPI** : Framework web asynchrone haute performance
- **Python 3.10+** : Langage de programmation principal
- **Pydantic** : Validation des donnÃ©es et gestion des configurations

### Stack IA/ML
- **LangChain** : Orchestration du pipeline RAG
- **ChromaDB** : Base de donnÃ©es vectorielle pour les embeddings
- **HuggingFace** : ModÃ¨les d'embeddings
- **Gemini/HuggingFace** : LLM pour la gÃ©nÃ©ration de rÃ©ponses
- **scikit-learn** : Clustering **KMeans** pour l'analyse des questions

### MLOps & DÃ©ploiement
- **MLflow** : Suivi d'expÃ©riences et registre de modÃ¨les
- **Kubernetes** : Orchestration de conteneurs (Minikube)
- **Lens Desktop** : Visualisation du cluster K8s
- **GitHub Actions** : Automatisation CI/CD

### Stockage de DonnÃ©es
- **PostgreSQL** : DonnÃ©es utilisateurs et historique des requÃªtes
- **ChromaDB** : Persistance des embeddings vectoriels

## Structure du Projet

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # Point d'entrÃ©e de l'application FastAPI
â”‚   â”œâ”€â”€ dependencies.py         # DÃ©pendances partagÃ©es (DB, auth)
â”‚   â”œâ”€â”€ schemas.py              # ModÃ¨les Pydantic
â”‚   â”œâ”€â”€ db/                     # ModÃ¨les et connexion base de donnÃ©es
â”‚   â”œâ”€â”€ model/                  # DÃ©finitions des modÃ¨les ML/IA
â”‚   â””â”€â”€ routes/                 # Points de terminaison API
â”‚       â”œâ”€â”€ auth.py            # Endpoints d'authentification
â”‚       â”œâ”€â”€ query.py           # Endpoints de requÃªtes RAG
â”‚       â””â”€â”€ history.py         # Endpoints d'historique
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ rag_pipeline.py        # ImplÃ©mentation du RAG
â”‚   â””â”€â”€ services/              # Logique mÃ©tier
â”œâ”€â”€ saved_model/               # ModÃ¨les entraÃ®nÃ©s et artefacts
â”œâ”€â”€ tests/                     # Tests unitaires et d'intÃ©gration
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/             # DÃ©finitions des pipelines CI/CD
â”œâ”€â”€ infra/                     # Manifestes Kubernetes
â”‚ 
â”œâ”€â”€ dataset/                   # Documentation PDF
â”œâ”€â”€ requirements.txt           # DÃ©pendances Python
â”œâ”€â”€ Dockerfile                 # DÃ©finition de l'image conteneur
â”œâ”€â”€ docker-compose.yml         # Configuration dÃ©veloppement local
â””â”€â”€ README.md                  # Ce fichier
```

## Installation

### PrÃ©requis

- Python 3.10 
- Docker et Docker Compose
- Minikube (pour le dÃ©ploiement Kubernetes)
- kubectl
- Lens Desktop (optionnel, pour la visualisation K8s)

### Configuration de l'Environnement de DÃ©veloppement Local

1. **Cloner le dÃ©pÃ´t**
   ```bash
   git clone git@github.com:Maryemelb/chatbot-rag.git
   cd rag-it-assistant
   ```

2. **CrÃ©er l'environnement virtuel**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Sur Windows: venv\Scripts\activate
   ```

3. **Installer les dÃ©pendances**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configurer les variables d'environnement**
   ```bash
   cp .env.example .env
   # Ã‰diter .env avec votre configuration
   ```

5. **Lancer l'application**
   ```bash
   uvicorn app.main:app --reload
   ```

L'API sera accessible Ã  `http://localhost:8000`

## âš™ï¸ Configuration

### Variables d'Environnement

CrÃ©er un fichier `.env` Ã  la racine du projet :

```env
# Base de donnÃ©es
copy .env.example file and complete it
```

## Utilisation

### Exemples d'Utilisation de l'API

**1. Inscription d'un Utilisateur**
```bash
curl -X POST "http://localhost:8000/auth/register" \
  -H "Content-Type: application/json" \
  -d '{
    "email": "utilisateur@entreprise.com",
    "password": "motdepassesecurise"
  }'
```

**2. Connexion**
```bash
curl -X POST "http://localhost:8000/auth/login" \
  -H "Content-Type: application/json" \
  -d '{
    "email": "utilisateur@entreprise.com",
    "password": "motdepassesecurise"
  }'
```

**3. Interroger le SystÃ¨me RAG**
```bash
curl -X POST "http://localhost:8000/query" \
  -H "Authorization: Bearer VOTRE_TOKEN_JWT" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Comment rÃ©initialiser un mot de passe utilisateur dans Active Directory ?"
  }'
```

**4. RÃ©cupÃ©rer l'Historique des RequÃªtes**
```bash
curl -X GET "http://localhost:8000/history" \
  -H "Authorization: Bearer VOTRE_TOKEN_JWT"
```

## Documentation API

Une fois l'application en cours d'exÃ©cution, accÃ©dez Ã  :

- **Documentation API interactive (Swagger UI)** : http://localhost:8000/docs


### Endpoints Principaux

| MÃ©thode | Endpoint | Description | Auth Requise |
|---------|----------|-------------|--------------|
| POST | `/auth/register` | CrÃ©er un nouveau compte utilisateur | Non |
| POST | `/auth/login` | Authentification et obtention du token JWT | Non |
| POST | `/query` | Poser une question au systÃ¨me RAG | Oui |
| GET | `/history` | RÃ©cupÃ©rer l'historique des requÃªtes | Oui |
| GET | `/health` | VÃ©rifier l'Ã©tat de santÃ© du service | Non |

## ğŸ”¬ Pipeline MLOps

### Suivi avec MLflow

Le systÃ¨me suit automatiquement :
- **ParamÃ¨tres** : TempÃ©rature du LLM, nom du modÃ¨le, taille des chunks, k de rÃ©cupÃ©ration
- **MÃ©triques** : Latence des rÃ©ponses, scores de similaritÃ©, prÃ©cision de rÃ©cupÃ©ration
- **Artefacts** : RÃ©ponses gÃ©nÃ©rÃ©es, chunks rÃ©cupÃ©rÃ©s, prompts

AccÃ¨s Ã  l'interface MLflow : `http://localhost:5000`

### Registre de ModÃ¨les

```python
# Enregistrer le pipeline RAG comme un modÃ¨le
import mlflow
mlflow.set_tracking_uri("http://localhost:5000")

with mlflow.start_run(run_name="rag-pipeline-v1"):
    mlflow.log_param("llm_model", "gemini-pro")
    mlflow.log_param("embedding_model", "all-MiniLM-L6-v2")
    mlflow.log_metric("avg_latency_ms", 450)
    
    # Logger le pipeline RAG
    mlflow.pyfunc.log_model("rag_model", python_model=rag_pipeline)
```



## Monitoring

### MÃ©triques de la Base de DonnÃ©es

La table `queries` trace :
- **latency_ms** : Temps de rÃ©ponse pour chaque requÃªte
- **cluster** : CatÃ©gorie de question (issu du clustering ML)
- **created_at** : Horodatage pour l'analyse des tendances

### VÃ©rification de SantÃ©

```bash
curl http://localhost:8000/health
```

RÃ©ponse :
```json
{
  "status": "healthy",
  "database": "connected",
  "vector_db": "ready",
  "timestamp": "2026-02-06T10:30:00Z"
}
```

### Surveillance des Performances

Surveiller les mÃ©triques clÃ©s :
- Latence moyenne des requÃªtes
- Latence au 95e percentile
- Questions par cluster
- Tendances d'engagement utilisateur

## Tests

### ExÃ©cuter Tous les Tests

```bash
pytest tests/ -v
```

### Couverture des Tests

```bash
pytest tests/ --cov=app --cov-report=html
```

### CatÃ©gories de Tests

- **Tests Unitaires** : Test des composants individuels


---

**DurÃ©e du Projet** : 26 janvier 2026 - 6 fÃ©vrier 2026  

## ModÃ¨le de DonnÃ©es PostgreSQL

### Table `users`

| Colonne | Type | Description |
|---------|------|-------------|
| `id` | INTEGER | Identifiant unique (clÃ© primaire) |
| `email` | VARCHAR | Email de l'utilisateur (unique) |
| `hashed_password` | VARCHAR | Mot de passe hashÃ© |
| `is_active` | BOOLEAN | Statut du compte |
| `created_at` | TIMESTAMP | Date de crÃ©ation |

### Table `queries`

| Colonne | Type | Description |
|---------|------|-------------|
| `id` | INTEGER | Identifiant unique (clÃ© primaire) |
| `user_id` | INTEGER | RÃ©fÃ©rence Ã  l'utilisateur (clÃ© Ã©trangÃ¨re) |
| `question` | TEXT | Question posÃ©e |
| `answer` | TEXT | RÃ©ponse gÃ©nÃ©rÃ©e par le RAG |
| `cluster` | INTEGER | NumÃ©ro de cluster (ML) |
| `latency_ms` | FLOAT | Temps de rÃ©ponse en ms |
| `created_at` | TIMESTAMP | Date et heure de la requÃªte |

### Relations

- Un utilisateur peut poser plusieurs questions (relation 1:N)
- Chaque question est associÃ©e Ã  un seul utilisateur
- Les clusters sont assignÃ©s aprÃ¨s analyse ML pÃ©riodique

## ğŸ”„ Pipeline CI/CD

Le workflow GitHub Actions automatise :

1. **DÃ©clencheurs** : Push sur `main` ou `develop`
2. **Ã‰tapes** :
   - Installation des dÃ©pendances Python
   - Linting du code (optionnel)
   - ExÃ©cution des tests unitaires et d'intÃ©gration
   - Construction de l'image Docker
   - Push vers le registre (Docker Hub / GitHub Container Registry)
   - DÃ©ploiement sur Kubernetes (si tests rÃ©ussis)

